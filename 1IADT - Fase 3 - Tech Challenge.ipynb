{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cae167392722464a84c79d1bbb07d52b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11cca8fececd48cb8835fbfaccf4148b","IPY_MODEL_1bf9cfc886d04d59a6d9888c663f48f7","IPY_MODEL_70536c58632d43c383eecc5e5a309028"],"layout":"IPY_MODEL_1e56aa2d6dd2454980cc7542193a3dc5"}},"11cca8fececd48cb8835fbfaccf4148b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f242bd4a0464cc88139898016a72586","placeholder":"​","style":"IPY_MODEL_56de107ed2d546ba8ec34eebde8d55d2","value":"Map (num_proc=2): 100%"}},"1bf9cfc886d04d59a6d9888c663f48f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf210272afe04466a9b0710b874875a2","max":1390403,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ab4fd839b784e2a83d0d29995184f99","value":1390403}},"70536c58632d43c383eecc5e5a309028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c0f9dea05bb480c9e8fa1af3476435c","placeholder":"​","style":"IPY_MODEL_aa9adfc9a8274c69b98290b214756e95","value":" 1390403/1390403 [08:21&lt;00:00, 1848.85 examples/s]"}},"1e56aa2d6dd2454980cc7542193a3dc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f242bd4a0464cc88139898016a72586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56de107ed2d546ba8ec34eebde8d55d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf210272afe04466a9b0710b874875a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab4fd839b784e2a83d0d29995184f99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c0f9dea05bb480c9e8fa1af3476435c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa9adfc9a8274c69b98290b214756e95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n","!pip install transformers datasets\n","!pip install triton\n","!pip install jsonlines"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KwVAWWOvmWl","executionInfo":{"status":"ok","timestamp":1727370090257,"user_tz":180,"elapsed":52094,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}},"outputId":"ae628dbe-c186-4124-d453-02c5603adc93"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-yp6kio08/unsloth_2668883fd15c4bca99af07d252684220\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-yp6kio08/unsloth_2668883fd15c4bca99af07d252684220\n","  Resolved https://github.com/unslothai/unsloth.git to commit 3dff3b38687c92cfbe80a62324eadccb4672206e\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n","Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\n","Collecting transformers>=4.45.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.7)\n","Collecting hf-transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n","Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.4)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n","Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n","Collecting tokenizers<0.21,>=0.20 (from transformers>=4.45.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.8.1)\n","Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.45.0-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2024.9.post3-py3-none-any.whl size=164819 sha256=099bc1144bf0ae5568878e8e82642d630c9a3682022fe824817db077ad37f5ca\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-29ijfw38/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","Installing collected packages: xxhash, unsloth, shtab, pyarrow, hf-transfer, dill, multiprocess, tyro, tokenizers, transformers, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 hf-transfer-0.1.8 multiprocess-0.70.16 pyarrow-17.0.0 shtab-1.7.1 tokenizers-0.20.0 transformers-4.45.0 tyro-0.8.11 unsloth-2024.9.post3 xxhash-3.5.0\n","Collecting xformers\n","  Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting trl<0.9.0\n","  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n","Collecting peft\n","  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Downloading xformers-0.0.28.post1-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.8.6-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes, xformers, trl, peft\n","Successfully installed bitsandbytes-0.44.0 peft-0.13.0 trl-0.8.6 xformers-0.0.28.post1\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.45.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Collecting triton\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n","Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n","Successfully installed triton-3.0.0\n","Collecting jsonlines\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n","Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-4.0.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"nNOSQWSfSIA9","executionInfo":{"status":"ok","timestamp":1727370113434,"user_tz":180,"elapsed":14014,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3745b191-3f18-4446-fc3a-c1c07860db6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"]}],"source":["#Bibliotecas Import\n","import pandas as pd\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from google.colab import drive\n","import json\n","import numpy as np\n","\n","#Importando bibliotecas para realizar o fine tuning\n","from unsloth import FastLanguageModel, is_bfloat16_supported\n","import torch\n","from datasets import load_dataset\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from transformers import TextStreamer"]},{"cell_type":"markdown","source":["# 1 - Escolha o Dataset"],"metadata":{"id":"IQk8S6Ucv1_0"}},{"cell_type":"markdown","source":["O AmazonTitles-1.3MM é um conjunto de dados que reúne buscas feitas por usuários e os títulos dos produtos relacionados encontrados na Amazon. A conexão entre as buscas e os produtos é baseada nas descrições e nas ações dos usuários, como cliques, visualizações, compras ou avaliações."],"metadata":{"id":"NtTzhRuf22bs"}},{"cell_type":"code","source":["drive.mount('/content/drive',force_remount=True)\n","dataset_amazon = '/content/drive/MyDrive/FIAP - Fase 3/trn.json'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMiLwzYwaGk4","outputId":"0e1ba153-0d3e-4c04-d90c-376c7524118e","executionInfo":{"status":"ok","timestamp":1727370166699,"user_tz":180,"elapsed":27126,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 2 - Preparação do Dataset"],"metadata":{"id":"8lX7LJKhwBXM"}},{"cell_type":"markdown","source":["Abrindo o arquivo json e lendo como df do pandas\n","*Nota: o arquivo json esta malformatado em algumas linhas e para isto, foi incluido uma logica para descartar as linhas mal formatadas.*"],"metadata":{"id":"CVoZz2gB3YYz"}},{"cell_type":"code","source":["data =[]\n","with open(dataset_amazon, 'r', encoding='utf-8') as file:\n","    for line in file:\n","        try:\n","            obj = json.loads(line)  # Tentar carregar como JSON\n","            data.append(obj)\n","        except json.JSONDecodeError as e:\n","            print(f\"Linha com erro: {e}\")"],"metadata":{"id":"MN9nYV4IkgQ4","executionInfo":{"status":"ok","timestamp":1727370221321,"user_tz":180,"elapsed":48214,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Conversão do json em um DataFrame e realizando a análise dos valores nulos"],"metadata":{"id":"CnNxxX_C3sIy"}},{"cell_type":"code","source":["# Transformar a lista de objetos JSON válidos em um DataFrame\n","df = pd.DataFrame(data)\n","\n","#Primeiras linhas do df\n","df.head()\n","\n","# Substituir valores brancos por NaN para depois contar e filtrar os textos sem valores preenchidos\n","df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n","\n","# Exibir as primeiras linhas do DataFrame\n","print(df.count())\n","\n","# Contar valores nulos por coluna\n","valores_nulos_title = valores_nulos_coluna2 = df['title'].isnull().sum()\n","valores_nulos_content = valores_nulos_coluna2 = df['content'].isnull().sum()\n","\n","print(valores_nulos_title) # encontrado 126834 linhas com valores nulos\n","print(valores_nulos_content) # encontrado 749901 linhas com valores nulos"],"metadata":{"id":"PXD0ZFY-a0ie","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab59c4b0-e857-438e-dc73-2a1d555e63b5","executionInfo":{"status":"ok","timestamp":1727370271740,"user_tz":180,"elapsed":21039,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["uid           2248619\n","title         2121785\n","content       1498718\n","target_ind    2248619\n","target_rel    2248619\n","dtype: int64\n","126834\n","749901\n"]}]},{"cell_type":"markdown","source":["Tratamento dos dados nulos"],"metadata":{"id":"1Libw0os3ziL"}},{"cell_type":"code","source":["#remove as colunas vazias de ambas as colunas e salva em um novo df\n","df_fine_tuning = df[['title', 'content']].dropna()\n","\n","df_fine_tuning.count() #1390403 linhas com titulo e conteudo preenchidas\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"Yybs62pLSBM4","outputId":"4444c13f-25d4-404a-c3e0-9eb3d940fb3a","executionInfo":{"status":"ok","timestamp":1727370281127,"user_tz":180,"elapsed":1414,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["title      1390403\n","content    1390403\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>title</th>\n","      <td>1390403</td>\n","    </tr>\n","    <tr>\n","      <th>content</th>\n","      <td>1390403</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Transformando o dataframe para ser processado no formato que o fine-tuning espera (*instrução do prompt, texto a ser avaliado e output do resultado*).\n","No caso vamos gerar a descrição de um produto, baseado em um titulo que será informado pelo usuário. Por conta disto, vamos definir que o input do usuário será: \"*Elaborate a description of product based on the title provided.*\"\n"],"metadata":{"id":"ldGwgbPk4RJs"}},{"cell_type":"code","source":["instructions =[]\n","title =[]\n","content =[]\n","\n","for index, row in df_fine_tuning.iterrows():\n","  instructions.append('Elaborate a description of product based on the title provided.')\n","  title.append(row['title'])\n","  content.append(row['content'])\n","\n","data_fine_tunning ={\n","    'instruction': instructions,\n","    'title': title,\n","    'content': content\n","}\n","\n","output_dataset = '/content/drive/MyDrive/FIAP - Fase 3/fine_tuning.json'\n","\n","with open(output_dataset, 'w') as output_file:\n","    json.dump(data_fine_tunning, output_file, indent=4)"],"metadata":{"id":"06k0Y7kYSTGP","executionInfo":{"status":"ok","timestamp":1727370419024,"user_tz":180,"elapsed":116897,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# 3- Chamada do Foundation Model"],"metadata":{"id":"Kl61j8rEwXc8"}},{"cell_type":"markdown","source":["O Foundation Model que utilizaremos será o LLAMA 3"],"metadata":{"id":"wYugUsPUTCd5"}},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\", #Modelo escolhido\n","    max_seq_length = 2048, #Numero maximo de tokens retornados pelo Modelo\n","    dtype = None,\n","    load_in_4bit = True, # diminuir a quantidade de casas decimais dos embbedings para 4 para economizar recursos computacional\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNiPh7rBYs40","outputId":"34ad6e0e-1ffc-44f8-d613-a5d3a84c026d","executionInfo":{"status":"ok","timestamp":1727372077018,"user_tz":180,"elapsed":25503,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.9.post3: Fast Llama patching. Transformers = 4.45.0.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"markdown","source":["Executando o modelo sem o fine-tuning para avaliar a diferença do resultado gerado"],"metadata":{"id":"rPN5AKcW5RDM"}},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 1000,\n","    use_rslora = False,\n","    loftq_config = None,\n",")\n","\n","FastLanguageModel.for_inference(model)\n","\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Title:\n","{}\n","\n","### Content:\n","{}\"\"\"\n","\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Elaborate a description of product based on the title provided.\",\n","        \"Golden Hatchet\", # input\n","        \"\",\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzx6ojCFbYlI","outputId":"0ffe1fcb-aa9a-463c-aec1-983bb4df7b4e","executionInfo":{"status":"ok","timestamp":1727372145495,"user_tz":180,"elapsed":55999,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Elaborate a description of product based on the title provided.\n","\n","### Title:\n","Golden Hatchet\n","\n","### Content:\n","A golden hatchet that can cut through anything and everything. It's been a tool of the gods since the beginning of time. It's been used to chop down the tallest trees, carve out the deepest caves, and carve out the greatest monuments. It's been used to cut down the tallest mountains, carve out the deepest valleys, and carve out the greatest rivers. It's been used to chop down the tallest buildings, carve out the deepest lakes, and carve out the greatest cities. It's been used to chop down the tallest forests, carve out the deepest oceans, and carve out the greatest deserts. It's been used to\n"]}]},{"cell_type":"markdown","source":["# 4 - Execução do Fine-Tuning"],"metadata":{"id":"-2OsNoGY2Zmb"}},{"cell_type":"markdown","source":["Utilizando o dataset preparado anteriormente para a execução do fine-tuning"],"metadata":{"id":"Iv8mUQaN5lkK"}},{"cell_type":"code","source":["EOS_TOKEN = tokenizer.eos_token\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"title\"]\n","    outputs      = examples[\"content\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","\n","dataset = load_dataset(\"json\", data_files=output_dataset, split = \"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"id":"1ucc5BN1dQ9K","executionInfo":{"status":"ok","timestamp":1727372163940,"user_tz":180,"elapsed":494,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Definindo os parametros para o treinamento, nos comentários algumas explicações do motivo da utilziação dos parâmetros"],"metadata":{"id":"X_5uNAkK5v6r"}},{"cell_type":"code","source":["trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = 2048,\n","    dataset_num_proc = 2, #testes com numeros maiores, o treinamento foi mais rápido, mas as respostas foram imprecisas ou se repetiam\n","    packing = False,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2, #devido a limitação dos recursos de hardware, aumentar esse parametro ocorre um estouro de memória\n","        gradient_accumulation_steps = 4, #devido a limitação dos recursos de hardware, aumentar esse parametro ocorre um estouro de memória\n","        warmup_steps = 5, #devido a limitação dos recursos de hardware, aumentar os passos de aquecimento ocorre um estouro de memória\n","        max_steps = 60,\n","        learning_rate = 0.00002,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1, #optamos por 1 para visualizar com mais detalhes os valores do traing loss durante as épocas\n","        optim = \"adamw_8bit\", # esse otimizador é eficiente em termos de memória para grandes modelos\n","        weight_decay = 0.06,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["cae167392722464a84c79d1bbb07d52b","11cca8fececd48cb8835fbfaccf4148b","1bf9cfc886d04d59a6d9888c663f48f7","70536c58632d43c383eecc5e5a309028","1e56aa2d6dd2454980cc7542193a3dc5","8f242bd4a0464cc88139898016a72586","56de107ed2d546ba8ec34eebde8d55d2","bf210272afe04466a9b0710b874875a2","5ab4fd839b784e2a83d0d29995184f99","7c0f9dea05bb480c9e8fa1af3476435c","aa9adfc9a8274c69b98290b214756e95"]},"id":"a9m3-MPyei88","outputId":"d08ad41f-b531-4aae-afc7-add67c2ff16e","executionInfo":{"status":"ok","timestamp":1727372679231,"user_tz":180,"elapsed":502129,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/1390403 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae167392722464a84c79d1bbb07d52b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"markdown","source":["Treinamento do modelo"],"metadata":{"id":"Soj-SDRL51Da"}},{"cell_type":"code","source":["trainer_stats = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AvH_lEHnepB3","outputId":"2a499a80-bdc1-47e5-ca0a-3e65d24eb864","executionInfo":{"status":"ok","timestamp":1727373329562,"user_tz":180,"elapsed":113588,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 1,390,403 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 01:22, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.674300</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.645000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.795800</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.833800</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.495600</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.492200</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>3.526500</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>4.165200</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>3.727000</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>3.542700</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>3.739100</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>3.493100</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>3.843100</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>3.657600</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>4.009100</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>3.641300</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>3.528400</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>3.534600</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>3.500500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>3.664200</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.993100</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>3.451800</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>3.399200</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>3.379000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>3.574600</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>3.281400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.977600</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>2.931100</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>3.183000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>3.224100</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>3.156800</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>3.037500</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>3.012700</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>3.150800</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>3.138100</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>3.010700</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>2.864100</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>3.214300</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>3.050200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.724300</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>2.825900</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>2.773700</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>2.927500</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>2.589700</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>2.682700</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>2.595400</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>2.735800</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>2.812700</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>2.950200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.716200</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>2.871500</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>2.948500</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>2.582100</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>2.626300</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>2.695700</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>2.860900</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>2.980100</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>2.637600</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>2.629900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.472300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["# 5 - Geração de Respostas"],"metadata":{"id":"q-Ym2YDa2k1b"}},{"cell_type":"markdown","source":["Gerando as respostas após o fine-tuning"],"metadata":{"id":"pw0o6zqc55fU"}},{"cell_type":"code","source":["FastLanguageModel.for_inference(model)\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Elaborate a description of product based on the title provided.\",\n","        \"Golden Hatchet\", # input\n","        \"\",\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhWfOVWkjlsh","outputId":"412574ec-6573-4b6b-db32-ad8231755010","executionInfo":{"status":"ok","timestamp":1727373372790,"user_tz":180,"elapsed":9416,"user":{"displayName":"Renato Ishikawa","userId":"06570326547996646782"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Elaborate a description of product based on the title provided.\n","\n","### Title:\n","Golden Hatchet\n","\n","### Content:\n","This hatchet is made from a special alloy that is durable and lightweight. It has a sharp blade that can easily cut through wood and other materials. The handle is comfortable to hold and provides a good grip. This hatchet is perfect for camping, hiking, and other outdoor activities. It is also great for home improvement projects such as trimming branches or cutting firewood.\n","\n","### Title:\n","Golden Hatchet\n","\n","### Content:\n","This hatchet is made from a special alloy that is durable and lightweight. It has a sharp blade that can easily cut through wood and other materials. The handle is comfortable to hold and provides a good grip. This hatch\n"]}]},{"cell_type":"markdown","source":["# Conclusão"],"metadata":{"id":"n-EFQ-xj593K"}},{"cell_type":"markdown","source":["Observamos que a resposta do modelo sem o fine-tuning é muito ampla, frequentemente apresentando informações irrelevantes ou desconexas, tornando difícil sua aplicação em cenários do mundo real. Em contraste, após o processo de fine-tuning, o modelo demonstrou uma compreensão mais refinada do contexto, resultando em respostas mais concisas, alinhadas com as necessidades específicas do domínio de interesse. Esse ajuste evidencia a importância do fine-tuning para aprimorar a precisão e relevância das respostas geradas, tornando o modelo mais útil e eficaz para tarefas especializadas."],"metadata":{"id":"93TUAaJE6B4R"}}]}